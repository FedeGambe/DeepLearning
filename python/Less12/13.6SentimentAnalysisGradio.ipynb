{"cells":[{"cell_type":"markdown","metadata":{"id":"FQ031nn0noN1"},"source":["# Sentiment Analysis Inference APP with GRADIO\n","Sentiment Analysis is the process of ‘computationally’ determining whether a piece of writing is positive, negative or neutral. It’s also known as opinion mining, deriving the opinion or attitude of a speaker."]},{"cell_type":"markdown","metadata":{"id":"I8rbx7UD4iv9"},"source":["<img src= \"https://frenzy86.s3.eu-west-2.amazonaws.com/python/nlp/sentiment.jpg\" width=1000>"]},{"cell_type":"code","source":["!pip install onnxruntime -q\n","!pip install gradio==4.15.0 -q"],"metadata":{"id":"RkbPgk37-oN2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709144832976,"user_tz":-60,"elapsed":28255,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"}},"outputId":"e87db478-f5bb-4b6e-c87c-b350f874094b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!wget https://frenzy86.s3.eu-west-2.amazonaws.com/python/nlp/tokenizer_sentiment.pkl\n","!wget https://frenzy86.s3.eu-west-2.amazonaws.com/python/nlp/sentiment-int8.onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-lm7xd2H1XP","executionInfo":{"status":"ok","timestamp":1709144839133,"user_tz":-60,"elapsed":841,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"}},"outputId":"a6103700-c55d-4956-9981-7404defd76eb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-28 18:27:18--  https://frenzy86.s3.eu-west-2.amazonaws.com/python/nlp/tokenizer_sentiment.pkl\n","Resolving frenzy86.s3.eu-west-2.amazonaws.com (frenzy86.s3.eu-west-2.amazonaws.com)... 3.5.245.154, 52.95.191.6, 52.95.191.62, ...\n","Connecting to frenzy86.s3.eu-west-2.amazonaws.com (frenzy86.s3.eu-west-2.amazonaws.com)|3.5.245.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 468214 (457K) [application/octet-stream]\n","Saving to: ‘tokenizer_sentiment.pkl’\n","\n","tokenizer_sentiment 100%[===================>] 457.24K  --.-KB/s    in 0.05s   \n","\n","2024-02-28 18:27:19 (8.72 MB/s) - ‘tokenizer_sentiment.pkl’ saved [468214/468214]\n","\n","--2024-02-28 18:27:19--  https://frenzy86.s3.eu-west-2.amazonaws.com/python/nlp/sentiment-int8.onnx\n","Resolving frenzy86.s3.eu-west-2.amazonaws.com (frenzy86.s3.eu-west-2.amazonaws.com)... 3.5.245.154, 52.95.191.6, 52.95.191.62, ...\n","Connecting to frenzy86.s3.eu-west-2.amazonaws.com (frenzy86.s3.eu-west-2.amazonaws.com)|3.5.245.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 67370259 (64M) [application/octet-stream]\n","Saving to: ‘sentiment-int8.onnx’\n","\n","sentiment-int8.onnx 100%[===================>]  64.25M  94.9MB/s    in 0.7s    \n","\n","2024-02-28 18:27:19 (94.9 MB/s) - ‘sentiment-int8.onnx’ saved [67370259/67370259]\n","\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"mgpv3gPgWD4h","executionInfo":{"status":"ok","timestamp":1709144867082,"user_tz":-60,"elapsed":6829,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"}}},"outputs":[],"source":["### MAIN SCRIPT OF INFERENCE  #######\n","# ONLY 3 LIB. REQUIRES\n","\n","import onnxruntime\n","import joblib\n","import numpy as np\n","\n","tokenizer = joblib.load(\"tokenizer_sentiment.pkl\")  # load tokenizer\n","onnx_model_path = \"sentiment-int8.onnx\"            # load model quantized int8\n","ort_session = onnxruntime.InferenceSession(onnx_model_path)\n","\n","def softmax(x):\n","    exp_x = np.exp(x - np.max(x))\n","    return exp_x / exp_x.sum(axis=-1, keepdims=True)\n","\n","def analyze_sentiment(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\")\n","\n","    # Prepare input data for ONNX model\n","    input_data = {\n","                \"input_ids\": inputs[\"input_ids\"].numpy(),\n","                \"attention_mask\": inputs[\"attention_mask\"].numpy()\n","                }\n","    output = ort_session.run(None, input_data)\n","    logits = np.array(output[0])\n","    probabilities = softmax(logits)\n","    sentiment_label = np.argmax(probabilities).item()\n","    sentiment_prob = np.max(probabilities).item()\n","    # Map sentiment labels to \"Negative\" and \"Positive\"\n","    if sentiment_label == 0:\n","        sentiment_str = \"Negative\"\n","    else:\n","        sentiment_str = \"Positive\"\n","    return sentiment_str, sentiment_prob"]},{"cell_type":"code","source":["## UI OF INFERENCE INSIDE COLAB\n","\n","import gradio as gr\n","\n","title = \"Sentiment Analysis Application\"\n","description = \"This application analyzes the sentiment of the given text with DistillBert Quantized (8-bit).\"\n","\n","demo = gr.Interface(\n","                    fn=analyze_sentiment,\n","                    inputs=gr.Textbox(placeholder=\"Write your text here...\", label=\"Input Text\"),\n","                    outputs=[gr.Textbox(label=\"Sentiment\"), gr.Textbox(label=\"Sentiment Probability\")],\n","                    title=title,\n","                    description=description,\n","                    allow_flagging= \"never\"\n","                    )\n","\n","demo.launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"cRT-i9fB-XH5","executionInfo":{"status":"ok","timestamp":1709145539109,"user_tz":-60,"elapsed":4748,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"}},"outputId":"dcdeb6bb-eea9-4012-d51f-a8d6fcc801c4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://1bb787aa1dae6d507b.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://1bb787aa1dae6d507b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[],"metadata":{"id":"cFG7RG_ODr7-"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}